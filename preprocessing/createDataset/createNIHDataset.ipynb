{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create NIH data-set.\n",
    "\n",
    "We don't use the handy short-hand methods that are used in other notebooks, because they don't exist anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard stuff\n",
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "# medical imaging stuff\n",
    "import dicom2nifti\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task specifics\n",
    "TASK = \"501\"\n",
    "TEST_IDS = [\"0001\", \"0009\", \"0017\", \"0026\", \"0033\", \"0041\", \"0049\", \"0057\", \"0065\", \"0073\", \"0081\", \"0082\"]\n",
    "create_images = False\n",
    "create_labels = False \n",
    "overwrite_datasetjson = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nih paths\n",
    "BASE_DIR = \"C:/Users/ikke_/OneDrive/Documenten/Thesis\"\n",
    "NIH_DIR = f'{BASE_DIR}/Data/NIH_pancreas_CT'\n",
    "\n",
    "# nnUnet paths\n",
    "TASK_NAME = f\"Task{TASK}\"\n",
    "DATA_DIR = f\"{BASE_DIR}/Data/nnUNet_raw_data_base\"\n",
    "TASK_DIR = f\"{DATA_DIR}/nnUNet_raw_data/{TASK_NAME}\"\n",
    "TRAIN_DATA_DIR = f\"{TASK_DIR}/imagesTr\"\n",
    "TRAIN_LABEL_DIR = f\"{TASK_DIR}/labelsTr\"\n",
    "TEST_DATA_DIR = f\"{TASK_DIR}/imagesTs\"\n",
    "TEST_LABEL_DIR = f\"{TASK_DIR}/labelsTs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders():\n",
    "    os.makedirs(TRAIN_DATA_DIR, exist_ok=True)\n",
    "    os.makedirs(TRAIN_LABEL_DIR, exist_ok=True)\n",
    "    os.makedirs(TEST_DATA_DIR, exist_ok=True)\n",
    "    os.makedirs(TEST_LABEL_DIR, exist_ok=True)\n",
    "\n",
    "def convert_images():\n",
    "    img_path = f'{NIH_DIR}/Pancreas-CT'\n",
    "\n",
    "    print(\"\\nCreating nn-Unet image data\\n\")\n",
    "    for scan_dir in os.listdir(img_path):\n",
    "        print(scan_dir)\n",
    "\n",
    "        # get scan id and path to the scan\n",
    "        scan_id = scan_dir[-4:]\n",
    "        curr_dir = img_path + \"/\"+ scan_dir\n",
    "\n",
    "        # NIH data is very nested so we go deep\n",
    "        for dir1 in os.listdir(curr_dir):\n",
    "            curr_dir += \"/\" + dir1\n",
    "            for dir2 in os.listdir(curr_dir):\n",
    "                curr_dir += \"/\" + dir2\n",
    "                \n",
    "                # Make nifty file from the current DICOM directory\n",
    "                print(f'Making nifti file from {curr_dir}, scan_id = {scan_id}')\n",
    "                print(TRAIN_DATA_DIR)\n",
    "                dicom2nifti.convert_directory(curr_dir, TRAIN_DATA_DIR, compression=True)\n",
    "                nifti_path = TRAIN_DATA_DIR+\"/none_pancreas.nii.gz\"\n",
    "                \n",
    "                # Reorient to LPS\n",
    "                img = sitk.ReadImage(nifti_path)\n",
    "                img = sitk.DICOMOrient(img, 'LPS')\n",
    "                \n",
    "                # Move to either train or test folder\n",
    "                if scan_id in TEST_IDS:\n",
    "                    file_path = TEST_DATA_DIR+f'/panc_{scan_id}_0000.nii.gz' # 0000 = hardcoded CT modality. We only have CT\n",
    "                else:\n",
    "                    file_path = TRAIN_DATA_DIR+f'/panc_{scan_id}_0000.nii.gz' # 0000 = hardcoded CT modality. We only have CT.\n",
    "\n",
    "                # Save \n",
    "                print(f'Saving to {file_path}')\n",
    "                sitk.WriteImage(img, file_path)\n",
    "\n",
    "def convert_labels():\n",
    "    label_path = f'{NIH_DIR}/labels'\n",
    "\n",
    "    print(\"\\nCreating nn-Unet label data\\n\")\n",
    "    for label in os.listdir(label_path):\n",
    "        \n",
    "        # Get label id\n",
    "        scan_id = label[5:9]\n",
    "        scan_path = os.path.join(label_path, label)\n",
    "        print(scan_id)\n",
    "        \n",
    "        # Reorient\n",
    "        label_img = sitk.ReadImage(scan_path)\n",
    "        label_img = sitk.DICOMOrient(label_img, 'LPS')\n",
    "\n",
    "        # Move to either train or test folder\n",
    "        if scan_id in TEST_IDS:\n",
    "            scan_path = os.path.join(TEST_LABEL_DIR, f'panc_{scan_id}.nii.gz')\n",
    "        else:\n",
    "            scan_path = os.path.join(TRAIN_LABEL_DIR, f'panc_{scan_id}.nii.gz')\n",
    "\n",
    "        # Save\n",
    "        print(f'Saving label to {scan_path}')\n",
    "        sitk.WriteImage(label_img, scan_path)\n",
    "\n",
    "def sanity_data_check():\n",
    "    # verify the amount of scans and labels\n",
    "    train_files = os.listdir(TRAIN_DATA_DIR)\n",
    "    label_files = os.listdir(TRAIN_LABEL_DIR)\n",
    "    print(\"train image files:\",len(train_files))\n",
    "    print(\"train label files:\",len(label_files))\n",
    "\n",
    "def generate_dataset_json(overwrite_json_file):\n",
    "    ''' Make a dataset.json file'''\n",
    "    json_file_exist = False\n",
    "    json_path = os.path.join(TASK_DIR,'dataset.json')\n",
    "\n",
    "    # check whether already exists\n",
    "    if os.path.exists(json_path):\n",
    "        print(f'dataset.json already exist! {json_path}')\n",
    "        json_file_exist = True\n",
    "\n",
    "    # create new dataset.json file\n",
    "    if json_file_exist==False or overwrite_json_file:\n",
    "\n",
    "        json_dict = OrderedDict()\n",
    "        json_dict['name'] = TASK_NAME\n",
    "        json_dict['description'] = \"500\"\n",
    "        json_dict['tensorImageSize'] = \"3D\"\n",
    "        json_dict['reference'] = \"TCIA, NIH\"\n",
    "        json_dict['licence'] = \"TCIA\"\n",
    "        json_dict['release'] = \"0.0\"\n",
    "        json_dict['modality'] = {\"0\": \"CT\"}\n",
    "        json_dict['labels'] = {\n",
    "            \"0\": \"background\",\n",
    "            \"1\": \"pancreas\"\n",
    "        }\n",
    "        \n",
    "        # get train and test filenames\n",
    "        train_ids = os.listdir(TRAIN_LABEL_DIR)\n",
    "        test_ids = os.listdir(TEST_LABEL_DIR)\n",
    "        json_dict['numTraining'] = len(train_ids)\n",
    "\n",
    "        # create raining and test entries \n",
    "        # NOTE: no modality in train image and labels in dataset.json!!\n",
    "        json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "        json_dict['test'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in test_ids]\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "        # Save\n",
    "        if os.path.exists(os.path.join(TASK_DIR,'dataset.json')):\n",
    "            if json_file_exist==False:\n",
    "                print('dataset.json created!')\n",
    "            else: \n",
    "                print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image files: 68\n",
      "train label files: 70\n",
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "# first, create folders\n",
    "create_folders()\n",
    "\n",
    "# convert scans and labels\n",
    "if create_images: convert_images()\n",
    "if create_labels: convert_labels()\n",
    "\n",
    "# sanity check on created files\n",
    "sanity_data_check()\n",
    "\n",
    "# create a description of the dataset\n",
    "generate_dataset_json(overwrite_datasetjson)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b125ce43c943fc1e14d9f62c3fffee4d275810a249a66947a8c399f2b69c2ea4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
