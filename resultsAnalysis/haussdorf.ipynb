{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates the haussdorf metrics we also use in some experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikke_\\OneDrive\\Documenten\\Thesis\\MasterThesis\\Code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nibabel as nib\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from nnunet.evaluation.metrics import *\n",
    "from util import management as mana\n",
    "from util import constants as con\n",
    "\n",
    "## zelf invullen\n",
    "hd_metric = hausdorff_distance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesis_dir = \"C:\\\\Users\\\\ikke_\\\\OneDrive\\\\Documenten\\\\Thesis\"\n",
    "filenames = {hausdorff_distance: \"haussdorfs.txt\", hausdorff_distance_95: \"haussdorf95s.txt\", dice: \"own_dice.txt\"}\n",
    "\n",
    "def get_dirs(task, config, trainer, task2 = None):\n",
    "    if task2 == None:\n",
    "        task2 = task\n",
    "    data_dir = f\"C:/Users/ikke_/OneDrive/Documenten/Thesis/Data/nnUNet_raw_data_base/nnUNet_raw_data/Task{task}\"\n",
    "    \n",
    "    res_dir = os.path.join(thesis_dir, \"Results\", str(task), config, trainer)\n",
    "    cv_dir = os.path.join(res_dir, \"cv_niftis_postprocessed\")\n",
    "    ts_dir = os.path.join(res_dir, \"inference\", str(task2), \"imagesTs\")\n",
    "\n",
    "    lab_ts = os.path.join(data_dir, \"labelsTs\")\n",
    "    lab_tr = os.path.join(data_dir, \"labelsTr\")\n",
    "\n",
    "    return cv_dir, ts_dir, lab_ts, lab_tr\n",
    "\n",
    "def get_dirs_p16(batch, task, config, trainer):\n",
    "    data_dir = f\"C:/Users/ikke_/OneDrive/Documenten/Thesis/Data/nnUNet_raw_data_base/nnUNet_raw_data\"\n",
    "    batch_dir = f\"{data_dir}/batch{batch}\"\n",
    "    \n",
    "    # test cases\n",
    "    lab_ts = os.path.join(batch_dir, \"labels\")\n",
    "    seg_ts = os.path.join(batch_dir, f\"labels_{task}\")\n",
    "\n",
    "    # validation cases\n",
    "    seg_cv = os.path.join(thesis_dir, \"Results\", str(task), config, trainer, \"cv_niftis_postprocessed\")\n",
    "    lab_cv = f\"{data_dir}/Task{task}/labelsTr\"\n",
    "\n",
    "    return lab_ts, seg_ts, seg_cv, lab_cv\n",
    "\n",
    "def calculate_hds(segmentation_path, label_path):\n",
    "    files = [i for i in os.listdir(segmentation_path) if i.endswith(\"nii.gz\")]\n",
    "    print(files)\n",
    "    hds = []\n",
    "    for file in files:\n",
    "        # load seg and label\n",
    "        seg_path = os.path.join(segmentation_path, file)\n",
    "        lab_path = os.path.join(label_path, file)\n",
    "        seg = np.array(nib.load(seg_path).dataobj)\n",
    "        lab = np.array(nib.load(lab_path).dataobj)\n",
    "\n",
    "        # compute HD\n",
    "        hd = hd_metric(seg, lab)\n",
    "        hds.append(hd)\n",
    "\n",
    "    # write results\n",
    "    fp = open(os.path.join(segmentation_path, filenames[hd_metric]), \"w\")\n",
    "    for item in hds:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    fp.write(f\"\\nMean: {np.nanmean(hds)}\")\n",
    "    fp.write(f\"\\nStd: {np.std(hds)}\")\n",
    "    fp.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate all the HD metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['panc_0001.nii.gz', 'panc_0002.nii.gz', 'panc_0003.nii.gz', 'panc_0004.nii.gz', 'panc_0005.nii.gz', 'panc_0007.nii.gz', 'panc_0009.nii.gz', 'panc_0010.nii.gz', 'panc_0021.nii.gz', 'panc_0022.nii.gz', 'panc_0023.nii.gz', 'panc_0024.nii.gz', 'panc_0025.nii.gz', 'panc_0026.nii.gz', 'panc_0027.nii.gz', 'panc_0028.nii.gz', 'panc_0029.nii.gz', 'panc_0030.nii.gz', 'panc_0031.nii.gz', 'panc_0032.nii.gz', 'panc_0033.nii.gz', 'panc_0034.nii.gz', 'panc_0036.nii.gz', 'panc_0037.nii.gz', 'panc_0038.nii.gz', 'panc_0040.nii.gz']\n",
      "['panc_0006.nii.gz', 'panc_0008.nii.gz', 'panc_0035.nii.gz', 'panc_0039.nii.gz']\n",
      "['panc_0001.nii.gz', 'panc_0002.nii.gz', 'panc_0003.nii.gz', 'panc_0004.nii.gz', 'panc_0005.nii.gz', 'panc_0007.nii.gz', 'panc_0009.nii.gz', 'panc_0010.nii.gz', 'panc_0021.nii.gz', 'panc_0022.nii.gz', 'panc_0023.nii.gz', 'panc_0024.nii.gz', 'panc_0025.nii.gz', 'panc_0026.nii.gz', 'panc_0027.nii.gz', 'panc_0028.nii.gz', 'panc_0029.nii.gz', 'panc_0030.nii.gz', 'panc_0031.nii.gz', 'panc_0032.nii.gz', 'panc_0033.nii.gz', 'panc_0034.nii.gz', 'panc_0036.nii.gz', 'panc_0037.nii.gz', 'panc_0038.nii.gz', 'panc_0040.nii.gz']\n",
      "['panc_0006.nii.gz', 'panc_0008.nii.gz', 'panc_0035.nii.gz', 'panc_0039.nii.gz']\n",
      "['panc_0001.nii.gz', 'panc_0002.nii.gz', 'panc_0003.nii.gz', 'panc_0004.nii.gz', 'panc_0005.nii.gz', 'panc_0007.nii.gz', 'panc_0009.nii.gz', 'panc_0010.nii.gz', 'panc_0021.nii.gz', 'panc_0022.nii.gz', 'panc_0023.nii.gz', 'panc_0024.nii.gz', 'panc_0025.nii.gz', 'panc_0026.nii.gz', 'panc_0027.nii.gz', 'panc_0028.nii.gz', 'panc_0029.nii.gz', 'panc_0030.nii.gz', 'panc_0031.nii.gz', 'panc_0032.nii.gz', 'panc_0033.nii.gz', 'panc_0034.nii.gz', 'panc_0036.nii.gz', 'panc_0037.nii.gz', 'panc_0038.nii.gz', 'panc_0040.nii.gz']\n",
      "['panc_0006.nii.gz', 'panc_0008.nii.gz', 'panc_0035.nii.gz', 'panc_0039.nii.gz']\n",
      "['panc_0001.nii.gz', 'panc_0002.nii.gz', 'panc_0003.nii.gz', 'panc_0004.nii.gz', 'panc_0005.nii.gz', 'panc_0007.nii.gz', 'panc_0009.nii.gz', 'panc_0010.nii.gz', 'panc_0021.nii.gz', 'panc_0022.nii.gz', 'panc_0023.nii.gz', 'panc_0024.nii.gz', 'panc_0025.nii.gz', 'panc_0026.nii.gz', 'panc_0027.nii.gz', 'panc_0028.nii.gz', 'panc_0029.nii.gz', 'panc_0030.nii.gz', 'panc_0031.nii.gz', 'panc_0032.nii.gz', 'panc_0033.nii.gz', 'panc_0034.nii.gz', 'panc_0036.nii.gz', 'panc_0037.nii.gz', 'panc_0038.nii.gz', 'panc_0040.nii.gz']\n",
      "['panc_0006.nii.gz', 'panc_0008.nii.gz', 'panc_0035.nii.gz', 'panc_0039.nii.gz']\n",
      "['panc_0001.nii.gz', 'panc_0002.nii.gz', 'panc_0003.nii.gz', 'panc_0004.nii.gz', 'panc_0005.nii.gz', 'panc_0007.nii.gz', 'panc_0009.nii.gz', 'panc_0010.nii.gz', 'panc_0021.nii.gz', 'panc_0022.nii.gz', 'panc_0023.nii.gz', 'panc_0024.nii.gz', 'panc_0025.nii.gz', 'panc_0026.nii.gz', 'panc_0027.nii.gz', 'panc_0028.nii.gz', 'panc_0029.nii.gz', 'panc_0030.nii.gz', 'panc_0031.nii.gz', 'panc_0032.nii.gz', 'panc_0033.nii.gz', 'panc_0034.nii.gz', 'panc_0036.nii.gz', 'panc_0037.nii.gz', 'panc_0038.nii.gz', 'panc_0040.nii.gz']\n",
      "['panc_0006.nii.gz', 'panc_0008.nii.gz', 'panc_0035.nii.gz', 'panc_0039.nii.gz']\n",
      "['panc_0001.nii.gz', 'panc_0002.nii.gz', 'panc_0003.nii.gz', 'panc_0004.nii.gz', 'panc_0005.nii.gz', 'panc_0007.nii.gz', 'panc_0009.nii.gz', 'panc_0010.nii.gz', 'panc_0021.nii.gz', 'panc_0022.nii.gz', 'panc_0023.nii.gz', 'panc_0024.nii.gz', 'panc_0025.nii.gz', 'panc_0026.nii.gz', 'panc_0027.nii.gz', 'panc_0028.nii.gz', 'panc_0029.nii.gz', 'panc_0030.nii.gz', 'panc_0031.nii.gz', 'panc_0032.nii.gz', 'panc_0033.nii.gz', 'panc_0034.nii.gz', 'panc_0036.nii.gz', 'panc_0037.nii.gz', 'panc_0038.nii.gz', 'panc_0040.nii.gz']\n",
      "['panc_0006.nii.gz', 'panc_0008.nii.gz', 'panc_0035.nii.gz', 'panc_0039.nii.gz']\n",
      "['panc_0001.nii.gz', 'panc_0002.nii.gz', 'panc_0003.nii.gz', 'panc_0004.nii.gz', 'panc_0005.nii.gz', 'panc_0007.nii.gz', 'panc_0009.nii.gz', 'panc_0010.nii.gz', 'panc_0021.nii.gz', 'panc_0022.nii.gz', 'panc_0023.nii.gz', 'panc_0024.nii.gz', 'panc_0025.nii.gz', 'panc_0026.nii.gz', 'panc_0027.nii.gz', 'panc_0028.nii.gz', 'panc_0029.nii.gz', 'panc_0030.nii.gz', 'panc_0031.nii.gz', 'panc_0032.nii.gz', 'panc_0033.nii.gz', 'panc_0034.nii.gz', 'panc_0036.nii.gz', 'panc_0037.nii.gz', 'panc_0038.nii.gz', 'panc_0040.nii.gz']\n",
      "['panc_0006.nii.gz', 'panc_0008.nii.gz', 'panc_0035.nii.gz', 'panc_0039.nii.gz']\n",
      "['panc_0001.nii.gz', 'panc_0002.nii.gz', 'panc_0003.nii.gz', 'panc_0004.nii.gz', 'panc_0005.nii.gz', 'panc_0007.nii.gz', 'panc_0009.nii.gz', 'panc_0010.nii.gz', 'panc_0021.nii.gz', 'panc_0022.nii.gz', 'panc_0023.nii.gz', 'panc_0024.nii.gz', 'panc_0025.nii.gz', 'panc_0026.nii.gz', 'panc_0027.nii.gz', 'panc_0028.nii.gz', 'panc_0029.nii.gz', 'panc_0030.nii.gz', 'panc_0031.nii.gz', 'panc_0032.nii.gz', 'panc_0033.nii.gz', 'panc_0034.nii.gz', 'panc_0036.nii.gz', 'panc_0037.nii.gz', 'panc_0038.nii.gz', 'panc_0040.nii.gz']\n",
      "['panc_0006.nii.gz', 'panc_0008.nii.gz', 'panc_0035.nii.gz', 'panc_0039.nii.gz']\n",
      "['panc_0001.nii.gz', 'panc_0002.nii.gz', 'panc_0003.nii.gz', 'panc_0004.nii.gz', 'panc_0005.nii.gz', 'panc_0007.nii.gz', 'panc_0009.nii.gz', 'panc_0010.nii.gz', 'panc_0021.nii.gz', 'panc_0022.nii.gz', 'panc_0023.nii.gz', 'panc_0024.nii.gz', 'panc_0025.nii.gz', 'panc_0026.nii.gz', 'panc_0027.nii.gz', 'panc_0028.nii.gz', 'panc_0029.nii.gz', 'panc_0030.nii.gz', 'panc_0031.nii.gz', 'panc_0032.nii.gz', 'panc_0033.nii.gz', 'panc_0034.nii.gz', 'panc_0036.nii.gz', 'panc_0037.nii.gz', 'panc_0038.nii.gz', 'panc_0040.nii.gz']\n",
      "['panc_0006.nii.gz', 'panc_0008.nii.gz', 'panc_0035.nii.gz', 'panc_0039.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "# NIH and MSD and BCV architecture experiment\n",
    "# for task in [con.TASK_501, con.TASK_510, con.TASK_525]:\n",
    "#     for trainer in [con.CLASSIC, con.HYBRID2, con.HYBRID2LR]:\n",
    "#         cv_dir, ts_dir, lab_ts, lab_tr = get_dirs(task, con.CONFIG_FULL, trainer)\n",
    "#         calculate_hds(cv_dir, lab_tr)\n",
    "#         calculate_hds(ts_dir, lab_ts)\n",
    "\n",
    "# # NIH architecture to 1500 experiment\n",
    "# for task in [con.TASK_501]:\n",
    "#     for trainer in [con.CLASSIC_1500, con.HYBRID2_1500, con.HYBRID2LR_1500]:\n",
    "#         cv_dir, ts_dir, lab_ts, lab_tr = get_dirs(task, con.CONFIG_FULL, trainer)\n",
    "#         calculate_hds(cv_dir, lab_tr)\n",
    "#         calculate_hds(ts_dir, lab_ts)\n",
    "\n",
    "# # BCV learning rate experiment\n",
    "# for task in [con.TASK_525, con.TASK_526, con.TASK_527]:\n",
    "#     for trainer in [con.CLASSIC, con.WEIGHT01, con.WEIGHT05, con.WEIGHT09]:\n",
    "#         if task == con.TASK_525 and trainer != con.CLASSIC: \n",
    "#             continue\n",
    "#         cv_dir, ts_dir, lab_ts, lab_tr = get_dirs(task, con.CONFIG_FULL, trainer)\n",
    "#         calculate_hds(cv_dir, lab_tr)\n",
    "#         calculate_hds(ts_dir, lab_ts)\n",
    "\n",
    "# Combined NIH/MSD dataset\n",
    "# for task in [con.TASK_800]:\n",
    "#     for trainer in [con.CLASSIC]:\n",
    "#         for task2 in [con.TASK_501, con.TASK_510]:\n",
    "#             cv_dir, ts_dir, lab_ts, lab_tr = get_dirs(task, con.CONFIG_FULL, trainer, task2)\n",
    "#             calculate_hds(lab_ts, ts_dir)\n",
    "\n",
    "# # doortrainen tot 1500 experiment\n",
    "# for task in [con.TASK_501]:\n",
    "#     for trainer in [con.CLASSIC_1500, con.HYBRID2_1500, con.HYBRID2LR_1500]:\n",
    "#         cv_dir, ts_dir, lab_ts, lab_tr = get_dirs(task, con.CONFIG_FULL, trainer)\n",
    "#         calculate_hds(cv_dir, lab_tr)\n",
    "#         calculate_hds(ts_dir, lab_ts)\n",
    "\n",
    "# # Combined NIH/MSD dataset\n",
    "# for task in [con.TASK_800]:\n",
    "#     for trainer in [con.CLASSIC]:\n",
    "#         for task2 in [con.TASK_510]:\n",
    "#             cv_dir, ts_dir, lab_ts, lab_tr = get_dirs(task, con.CONFIG_FULL, trainer, task2)\n",
    "#             lab_ts = f\"C:/Users/ikke_/OneDrive/Documenten/Thesis/Data/nnUNet_raw_data_base/nnUNet_raw_data/Task510/labelsTs\"\n",
    "#             calculate_hds(lab_ts, ts_dir)\n",
    "\n",
    "# #for task in [con.TASK_600, con.TASK_601]:\n",
    "# for task in [con.TASK_601]:\n",
    "#     for trainer in [con.CLASSIC]:\n",
    "#         # calculate amos itself\n",
    "#         # cv_dir, ts_dir, lab_ts, lab_tr = get_dirs(task, con.CONFIG_FULL, trainer)\n",
    "#         # calculate_hds(cv_dir, lab_tr)\n",
    "#         # calculate_hds(ts_dir, lab_ts)\n",
    "\n",
    "#         # calculate MSD\n",
    "#         cv_dir, ts_dir, lab_ts, lab_tr = get_dirs(task, con.CONFIG_FULL, trainer, con.TASK_510)\n",
    "#         lab_ts = f\"C:/Users/ikke_/OneDrive/Documenten/Thesis/Data/nnUNet_raw_data_base/nnUNet_raw_data/Task510/labelsTs\"\n",
    "#         calculate_hds(ts_dir, lab_ts)\n",
    "\n",
    "# hd_metric = hausdorff_distance\n",
    "# for task in [con.TASK_600, con.TASK_601]:\n",
    "#     for trainer in [con.CLASSIC]:\n",
    "#         # calculate amos itself\n",
    "#         # cv_dir, ts_dir, lab_ts, lab_tr = get_dirs(task, con.CONFIG_FULL, trainer)\n",
    "#         # calculate_hds(cv_dir, lab_tr)\n",
    "#         # calculate_hds(ts_dir, lab_ts)\n",
    "\n",
    "#         # calculate MSD\n",
    "#         cv_dir, ts_dir, lab_ts, lab_tr = get_dirs(task, con.CONFIG_FULL, trainer, con.TASK_510)\n",
    "#         lab_ts = f\"C:/Users/ikke_/OneDrive/Documenten/Thesis/Data/nnUNet_raw_data_base/nnUNet_raw_data/Task510/labelsTs\"\n",
    "#         calculate_hds(ts_dir, lab_ts)\n",
    "\n",
    "# # P16 batch 1\n",
    "# for task in [con.TASK_610, con.TASK_611]:\n",
    "#         lab_ts, seg_ts, seg_cv, lab_cv = get_dirs_p16(1, task, con.CONFIG_FULL, con.CLASSIC)\n",
    "#         # calculate HDs on batch 1\n",
    "#         if task != con.TASK_612:\n",
    "#                 calculate_hds(lab_ts, seg_ts)\n",
    "#         # calculate HDs on its own validation cases\n",
    "#         calculate_hds(seg_cv, lab_cv)\n",
    "\n",
    "# # P16 batch 2\n",
    "# for task in [con.TASK_613]:#[con.TASK_610, con.TASK_611, con.TASK_612, con.TASK_613]:\n",
    "#         lab_ts, seg_ts, seg_cv, lab_cv = get_dirs_p16(2, task, con.CONFIG_FULL, con.CLASSIC)\n",
    "#          # calculate HDs on batch 2\n",
    "#         if task != con.TASK_613:\n",
    "#                 calculate_hds(seg_ts, lab_ts) \n",
    "#         # let 613 calculate HDs on its own validation cases\n",
    "#         else:\n",
    "#                 calculate_hds(seg_cv, lab_cv) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b125ce43c943fc1e14d9f62c3fffee4d275810a249a66947a8c399f2b69c2ea4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
